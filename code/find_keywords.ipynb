{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.labeling import labeling_function\n",
    "\n",
    "@labeling_function()\n",
    "def lf_contains_link(x):\n",
    "# Return a label of SPAM if \"http\" in comment text, otherwise ABSTAIN\n",
    "    return SPAM if \"http\" in x.text.lower() else ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import os\n",
    "\n",
    "# Make sure we're running from the spam/ directory\n",
    "if os.path.basename(os.getcwd()) == \"snorkel-tutorials\":\n",
    "    os.chdir(\"spam\")\n",
    "\n",
    "# Turn off TensorFlow logging messages\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "# For reproducibility\n",
    "os.environ[\"PYTHONHASHSEED\"] = \"0\"\n",
    "\n",
    "\n",
    "\n",
    "# %% [markdown] {\"tags\": [\"md-exclude\"]}\n",
    "# If you want to display all comment text untruncated, change `DISPLAY_ALL_TEXT` to `True` below.\n",
    "\n",
    "# %% {\"tags\": [\"md-exclude\"]}\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "DISPLAY_ALL_TEXT = False\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", 0 if DISPLAY_ALL_TEXT else 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "flood2018 = pd.read_csv('../output/flood_tweets_by_city_hour/flood_tweets_by_city_hour_2018.csv')\n",
    "FLOOD = 1\n",
    "OTHER = 0\n",
    "ABSTAIN = -1\n",
    "HAM = 0\n",
    "SPAM = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3145: DtypeWarning: Columns (0,1) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "flood2018 = pd.read_csv('../output/coastal_city_by_day/2014_08_04.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.labeling import labeling_function\n",
    "\n",
    "@labeling_function()\n",
    "def check(x):\n",
    "    return FLOOD if \"flood\" in x.text.lower() else ABSTAIN\n",
    "@labeling_function()\n",
    "def check_out(x):\n",
    "    return FLOOD if \"flooding\" in x.text.lower() else ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = flood2018\n",
    "df_train = flood2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>msa</th>\n",
       "      <th>GEOID</th>\n",
       "      <th>text</th>\n",
       "      <th>place.name</th>\n",
       "      <th>favorites</th>\n",
       "      <th>retweets</th>\n",
       "      <th>userid</th>\n",
       "      <th>Probability_Flooding_V2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2014</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Salisbury, MD-DE</td>\n",
       "      <td>41540.0</td>\n",
       "      <td>Been home for like an hour. Bored already.</td>\n",
       "      <td>Delaware, USA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.917781e+08</td>\n",
       "      <td>0.179647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2014</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Portland-Vancouver-Hillsboro, OR-WA</td>\n",
       "      <td>38900.0</td>\n",
       "      <td>@mayak46 I dunno if many people will look at t...</td>\n",
       "      <td>Beaverton, OR</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.934621e+07</td>\n",
       "      <td>0.142195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2014</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>New York-Newark-Jersey City, NY-NJ-PA</td>\n",
       "      <td>35620.0</td>\n",
       "      <td>Got smoked by an 1100 whp lamboðŸ˜‚</td>\n",
       "      <td>Hauppauge, NY</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.189612e+09</td>\n",
       "      <td>0.100916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2014</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>New York-Newark-Jersey City, NY-NJ-PA</td>\n",
       "      <td>35620.0</td>\n",
       "      <td>Watching the process of making Tobasco Sauce; ...</td>\n",
       "      <td>New Rochelle, NY</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.911203e+08</td>\n",
       "      <td>0.079616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2014</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Miami-Fort Lauderdale-West Palm Beach, FL</td>\n",
       "      <td>33100.0</td>\n",
       "      <td>ï¿½@basiclorenaa: @andrewww_21 sing him a songï¿½ ...</td>\n",
       "      <td>Tamiami, FL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.486545e+09</td>\n",
       "      <td>0.069867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455339</th>\n",
       "      <td>1331001</td>\n",
       "      <td>2014</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>Miami-Fort Lauderdale-West Palm Beach, FL</td>\n",
       "      <td>33100.0</td>\n",
       "      <td>Wind 0.7 mph SSW. Barometer 29.88 in, Falling ...</td>\n",
       "      <td>Florida, USA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.998853e+07</td>\n",
       "      <td>0.467805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455340</th>\n",
       "      <td>1331002</td>\n",
       "      <td>2014</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>Washington-Arlington-Alexandria, DC-VA-MD-WV</td>\n",
       "      <td>47900.0</td>\n",
       "      <td>@Naytrillsx_ it shouldn't be that serious if t...</td>\n",
       "      <td>Laurel, MD</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.376327e+08</td>\n",
       "      <td>0.135989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455341</th>\n",
       "      <td>1331003</td>\n",
       "      <td>2014</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>Washington-Arlington-Alexandria, DC-VA-MD-WV</td>\n",
       "      <td>47900.0</td>\n",
       "      <td>59 users and 116 tweets (29 RTs) in 6 minutes ...</td>\n",
       "      <td>Washington, DC</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.180025e+09</td>\n",
       "      <td>0.220082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455342</th>\n",
       "      <td>1331004</td>\n",
       "      <td>2014</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>Los Angeles-Long Beach-Anaheim, CA</td>\n",
       "      <td>31080.0</td>\n",
       "      <td>@awskarito_ @diselCA @Fonzyman yuuup that's ex...</td>\n",
       "      <td>Los Angeles, CA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.167422e+09</td>\n",
       "      <td>0.135372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455343</th>\n",
       "      <td>1331005</td>\n",
       "      <td>2014</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>Philadelphia-Camden-Wilmington, PA-NJ-DE-MD</td>\n",
       "      <td>37980.0</td>\n",
       "      <td>'I got that @justinbieber please beliebe it' a...</td>\n",
       "      <td>Pennsylvania, USA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.060136e+08</td>\n",
       "      <td>0.271547</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1455344 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0  year  month  day  hour  \\\n",
       "0                0  2014    8.0  4.0   0.0   \n",
       "1                1  2014    8.0  4.0   0.0   \n",
       "2                2  2014    8.0  4.0   0.0   \n",
       "3                3  2014    8.0  4.0   0.0   \n",
       "4                4  2014    8.0  4.0   0.0   \n",
       "...            ...   ...    ...  ...   ...   \n",
       "1455339    1331001  2014    8.0  4.0  23.0   \n",
       "1455340    1331002  2014    8.0  4.0  23.0   \n",
       "1455341    1331003  2014    8.0  4.0  23.0   \n",
       "1455342    1331004  2014    8.0  4.0  23.0   \n",
       "1455343    1331005  2014    8.0  4.0  23.0   \n",
       "\n",
       "                                                  msa    GEOID  \\\n",
       "0                                    Salisbury, MD-DE  41540.0   \n",
       "1                 Portland-Vancouver-Hillsboro, OR-WA  38900.0   \n",
       "2               New York-Newark-Jersey City, NY-NJ-PA  35620.0   \n",
       "3               New York-Newark-Jersey City, NY-NJ-PA  35620.0   \n",
       "4           Miami-Fort Lauderdale-West Palm Beach, FL  33100.0   \n",
       "...                                               ...      ...   \n",
       "1455339     Miami-Fort Lauderdale-West Palm Beach, FL  33100.0   \n",
       "1455340  Washington-Arlington-Alexandria, DC-VA-MD-WV  47900.0   \n",
       "1455341  Washington-Arlington-Alexandria, DC-VA-MD-WV  47900.0   \n",
       "1455342            Los Angeles-Long Beach-Anaheim, CA  31080.0   \n",
       "1455343   Philadelphia-Camden-Wilmington, PA-NJ-DE-MD  37980.0   \n",
       "\n",
       "                                                      text         place.name  \\\n",
       "0               Been home for like an hour. Bored already.      Delaware, USA   \n",
       "1        @mayak46 I dunno if many people will look at t...      Beaverton, OR   \n",
       "2                         Got smoked by an 1100 whp lamboðŸ˜‚      Hauppauge, NY   \n",
       "3        Watching the process of making Tobasco Sauce; ...   New Rochelle, NY   \n",
       "4        ï¿½@basiclorenaa: @andrewww_21 sing him a songï¿½ ...        Tamiami, FL   \n",
       "...                                                    ...                ...   \n",
       "1455339  Wind 0.7 mph SSW. Barometer 29.88 in, Falling ...       Florida, USA   \n",
       "1455340  @Naytrillsx_ it shouldn't be that serious if t...         Laurel, MD   \n",
       "1455341  59 users and 116 tweets (29 RTs) in 6 minutes ...     Washington, DC   \n",
       "1455342  @awskarito_ @diselCA @Fonzyman yuuup that's ex...    Los Angeles, CA   \n",
       "1455343  'I got that @justinbieber please beliebe it' a...  Pennsylvania, USA   \n",
       "\n",
       "         favorites  retweets        userid  Probability_Flooding_V2  \n",
       "0              0.0       0.0  2.917781e+08                 0.179647  \n",
       "1              0.0       0.0  5.934621e+07                 0.142195  \n",
       "2              0.0       0.0  2.189612e+09                 0.100916  \n",
       "3              0.0       0.0  3.911203e+08                 0.079616  \n",
       "4              0.0       0.0  1.486545e+09                 0.069867  \n",
       "...            ...       ...           ...                      ...  \n",
       "1455339        0.0       0.0  9.998853e+07                 0.467805  \n",
       "1455340        0.0       0.0  2.376327e+08                 0.135989  \n",
       "1455341        0.0       0.0  1.180025e+09                 0.220082  \n",
       "1455342        0.0       0.0  1.167422e+09                 0.135372  \n",
       "1455343        0.0       0.0  3.060136e+08                 0.271547  \n",
       "\n",
       "[1455344 rows x 13 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-f45937856810>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df_train' is not defined"
     ]
    }
   ],
   "source": [
    "# We pull out the label vectors for ease of use later\n",
    "Y_test = df_test.label.values\n",
    "df_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-02b66f19fab9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mapplier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPandasLFApplier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlfs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlfs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mL_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapplier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df_train' is not defined"
     ]
    }
   ],
   "source": [
    "from snorkel.labeling import PandasLFApplier\n",
    "\n",
    "lfs = [check_out, check]\n",
    "\n",
    "applier = PandasLFApplier(lfs=lfs)\n",
    "L_train = applier.apply(df=df_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'load_spam_dataset' from 'utils' (/usr/local/lib/python3.8/site-packages/utils/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-ffdc08d0a723>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;31m# %%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_spam_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_spam_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'load_spam_dataset' from 'utils' (/usr/local/lib/python3.8/site-packages/utils/__init__.py)"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# The class distribution varies slightly between `SPAM` and `HAM`, but they're approximately class-balanced.\n",
    "\n",
    "# %%\n",
    "# For clarity, we define constants to represent the class labels for spam, ham, and abstaining.\n",
    "\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 2. Writing Labeling Functions (LFs)\n",
    "\n",
    "# %% [markdown]\n",
    "# ### A gentle introduction to LFs\n",
    "\n",
    "# %% [markdown]\n",
    "# **Labeling functions (LFs) help users encode domain knowledge and other supervision sources programmatically.**\n",
    "#\n",
    "# LFs are heuristics that take as input a data point and either assign a label to it (in this case, `HAM` or `SPAM`) or abstain (don't assign any label). Labeling functions can be *noisy*: they don't have perfect accuracy and don't have to label every data point.\n",
    "# Moreover, different labeling functions can overlap (label the same data point) and even conflict (assign different labels to the same data point). This is expected, and we demonstrate how we deal with this later.\n",
    "#\n",
    "# Because their only requirement is that they map a data point a label (or abstain), they can wrap a wide variety of forms of supervision. Examples include, but are not limited to:\n",
    "# * *Keyword searches*: looking for specific words in a sentence\n",
    "# * *Pattern matching*: looking for specific syntactical patterns\n",
    "# * *Third-party models*: using an pre-trained model (usually a model for a different task than the one at hand)\n",
    "# * *Distant supervision*: using external knowledge base\n",
    "# * *Crowdworker labels*: treating each crowdworker as a black-box function that assigns labels to subsets of the data\n",
    "\n",
    "# %% [markdown]\n",
    "# ### Recommended practice for LF development\n",
    "\n",
    "# %% [markdown]\n",
    "# Typical LF development cycles include multiple iterations of ideation, refining, evaluation, and debugging.\n",
    "# A typical cycle consists of the following steps:\n",
    "#\n",
    "# 1. Look at examples to generate ideas for LFs\n",
    "# 1. Write an initial version of an LF\n",
    "# 1. Spot check its performance by looking at its output on data points in the training set (or development set if available)\n",
    "# 1. Refine and debug to improve coverage or accuracy as necessary\n",
    "#\n",
    "# Our goal for LF development is to create a high quality set of training labels for our unlabeled dataset,\n",
    "# not to label everything or directly create a model for inference using the LFs.\n",
    "# The training labels are used to train a separate discriminative model (in this case, one which just uses the comment text) in order to generalize to new, unseen data points.\n",
    "# Using this model, we can make predictions for data points that our LFs don't cover.\n",
    "#\n",
    "# We'll walk through the development of two LFs using basic analysis tools in Snorkel, then provide a full set of LFs that we developed for this tutorial.\n",
    "\n",
    "# %% [markdown]\n",
    "# ### a) Exploring the training set for initial ideas\n",
    "\n",
    "# %% [markdown]\n",
    "# We'll start by looking at 20 random data points from the `train` set to generate some ideas for LFs.\n",
    "\n",
    "# %%\n",
    "df_train[[\"author\", \"text\", \"video\"]].sample(20, random_state=2)\n",
    "\n",
    "# %% [markdown]\n",
    "# One dominant pattern in the comments that look like spam (which we might know from prior domain experience, or from inspection of a few training data points) is the use of the phrase \"check out\" (e.g. \"check out my channel\").\n",
    "# Let's start with that.\n",
    "\n",
    "# %% [markdown]\n",
    "# ### b) Writing an LF to identify spammy comments that use the phrase \"check out\"\n",
    "\n",
    "# %% [markdown]\n",
    "# Labeling functions in Snorkel are created with the\n",
    "# [`@labeling_function` decorator](https://snorkel.readthedocs.io/en/master/packages/_autosummary/labeling/snorkel.labeling.labeling_function.html).\n",
    "# The [decorator](https://realpython.com/primer-on-python-decorators/) can be applied to _any Python function_ that returns a label for a single data point.\n",
    "#\n",
    "# Let's start developing an LF to catch instances of commenters trying to get people to \"check out\" their channel, video, or website.\n",
    "# We'll start by just looking for the exact string `\"check out\"` in the text, and see how that compares to looking for just `\"check\"` in the text.\n",
    "# For the two versions of our rule, we'll write a Python function over a single data point that express it, then add the decorator.\n",
    "\n",
    "# %%\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# To apply one or more LFs that we've written to a collection of data points, we use an\n",
    "# [`LFApplier`](https://snorkel.readthedocs.io/en/master/packages/_autosummary/labeling/snorkel.labeling.LFApplier.html).\n",
    "# Because our data points are represented with a Pandas DataFrame in this tutorial, we use the\n",
    "# [`PandasLFApplier`](https://snorkel.readthedocs.io/en/master/packages/_autosummary/labeling/snorkel.labeling.PandasLFApplier.html).\n",
    "# Correspondingly, a single data point `x` that's passed into our LFs will be a [Pandas `Series` object](https://pandas.pydata.org/pandas-docs/stable/reference/series.html).\n",
    "#\n",
    "# It's important to note that these LFs will work for any object with an attribute named `text`, not just Pandas objects.\n",
    "# Snorkel has several other appliers for different data point collection types which you can browse in the [API documentation](https://snorkel.readthedocs.io/en/master/packages/labeling.html).\n",
    "#\n",
    "# The output of the `apply(...)` method is a ***label matrix***, a fundamental concept in Snorkel.\n",
    "# It's a NumPy array `L` with one column for each LF and one row for each data point, where `L[i, j]` is the label that the `j`th labeling function output for the `i`th data point.\n",
    "# We'll create a label matrix for the `train` set.\n",
    "\n",
    "# %% {\"tags\": [\"md-exclude-output\"]}\n",
    "from snorkel.labeling import PandasLFApplier\n",
    "\n",
    "lfs = [check_out, check]\n",
    "\n",
    "applier = PandasLFApplier(lfs=lfs)\n",
    "L_train = applier.apply(df=df_train)\n",
    "\n",
    "# %%\n",
    "L_train\n",
    "\n",
    "# %% [markdown]\n",
    "# ### c) Evaluate performance on training set\n",
    "\n",
    "# %% [markdown]\n",
    "# We can easily calculate the coverage of these LFs (i.e., the percentage of the dataset that they label) as follows:\n",
    "\n",
    "# %%\n",
    "coverage_check_out, coverage_check = (L_train != ABSTAIN).mean(axis=0)\n",
    "print(f\"check_out coverage: {coverage_check_out * 100:.1f}%\")\n",
    "print(f\"check coverage: {coverage_check * 100:.1f}%\")\n",
    "\n",
    "# %% [markdown]\n",
    "# Lots of statistics about labeling functions &mdash; like coverage &mdash; are useful when building any Snorkel application.\n",
    "# So Snorkel provides tooling for common LF analyses using the\n",
    "# [`LFAnalysis` utility](https://snorkel.readthedocs.io/en/master/packages/_autosummary/labeling/snorkel.labeling.LFAnalysis.html).\n",
    "# We report the following summary statistics for multiple LFs at once:\n",
    "#\n",
    "# * **Polarity**: The set of unique labels this LF outputs (excluding abstains)\n",
    "# * **Coverage**: The fraction of the dataset the LF labels\n",
    "# * **Overlaps**: The fraction of the dataset where this LF and at least one other LF label\n",
    "# * **Conflicts**: The fraction of the dataset where this LF and at least one other LF label and disagree\n",
    "# * **Correct**: The number of data points this LF labels correctly (if gold labels are provided)\n",
    "# * **Incorrect**: The number of data points this LF labels incorrectly (if gold labels are provided)\n",
    "# * **Empirical Accuracy**: The empirical accuracy of this LF (if gold labels are provided)\n",
    "#\n",
    "# For *Correct*, *Incorrect*, and *Empirical Accuracy*, we don't want to penalize the LF for data points where it abstained.\n",
    "# We calculate these statistics only over those data points where the LF output a label.\n",
    "# **Note that in our current setup, we can't compute these statistics because we don't have any ground-truth labels (other than in the test set, which we cannot look at). Not to worryâ€”Snorkel's `LabelModel` will estimate them without needing any ground-truth labels in the next step!**\n",
    "\n",
    "# %%\n",
    "from snorkel.labeling import LFAnalysis\n",
    "\n",
    "LFAnalysis(L=L_train, lfs=lfs).lf_summary()\n",
    "\n",
    "# %% [markdown]\n",
    "# We might want to pick the `check` rule, since `check` has higher coverage. Let's take a look at 10 random `train` set data points where `check` labeled `SPAM` to see if it matches our intuition or if we can identify some false positives.\n",
    "\n",
    "# %%\n",
    "df_train.iloc[L_train[:, 1] == SPAM].sample(10, random_state=1)\n",
    "\n",
    "# %% [markdown]\n",
    "# No clear false positives here, but many look like they could be labeled by `check_out` as well.\n",
    "#\n",
    "# Let's see 10 data points where `check_out` abstained, but `check` labeled. We can use the`get_label_buckets(...)` to group data points by their predicted label and/or true labels.\n",
    "\n",
    "# %%\n",
    "from snorkel.analysis import get_label_buckets\n",
    "\n",
    "buckets = get_label_buckets(L_train[:, 0], L_train[:, 1])\n",
    "df_train.iloc[buckets[(ABSTAIN, SPAM)]].sample(10, random_state=1)\n",
    "\n",
    "# %% [markdown]\n",
    "# Most of these seem like small modifications of \"check out\", like \"check me out\" or \"check it out\".\n",
    "# Can we get the best of both worlds?\n",
    "\n",
    "# %% [markdown]\n",
    "# ### d) Balance accuracy and coverage\n",
    "\n",
    "# %% [markdown]\n",
    "# Let's see if we can use regular expressions to account for modifications of \"check out\" and get the coverage of `check` plus the accuracy of `check_out`.\n",
    "\n",
    "# %%\n",
    "import re\n",
    "\n",
    "\n",
    "@labeling_function()\n",
    "def regex_check_out(x):\n",
    "    return SPAM if re.search(r\"check.*out\", x.text, flags=re.I) else ABSTAIN\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# Again, let's generate our label matrices and see how we do.\n",
    "\n",
    "# %% {\"tags\": [\"md-exclude-output\"]}\n",
    "lfs = [check_out, check, regex_check_out]\n",
    "\n",
    "applier = PandasLFApplier(lfs=lfs)\n",
    "L_train = applier.apply(df=df_train)\n",
    "\n",
    "# %%\n",
    "LFAnalysis(L=L_train, lfs=lfs).lf_summary()\n",
    "\n",
    "# %% [markdown]\n",
    "# We've split the difference in `train` set coverageâ€”this looks promising!\n",
    "# Let's verify that we corrected our false positive from before.\n",
    "\n",
    "# %% [markdown]\n",
    "# To understand the coverage difference between `check` and `regex_check_out`, let's take a look at 10 data points from the `train` set.\n",
    "# Remember: coverage isn't always good.\n",
    "# Adding false positives will increase coverage.\n",
    "\n",
    "# %%\n",
    "buckets = get_label_buckets(L_train[:, 1], L_train[:, 2])\n",
    "df_train.iloc[buckets[(SPAM, ABSTAIN)]].sample(10, random_state=1)\n",
    "\n",
    "# %% [markdown]\n",
    "# Most of these are SPAM, but a good number are false positives.\n",
    "# **To keep precision high (while not sacrificing much in terms of coverage), we'd choose our regex-based rule.**\n",
    "\n",
    "# %% [markdown]\n",
    "# ### e) Writing an LF that uses a third-party model\n",
    "\n",
    "# %% [markdown]\n",
    "# The LF interface is extremely flexible, and can wrap existing models.\n",
    "# A common technique is to use a commodity model trained for other tasks that are related to, but not the same as, the one we care about.\n",
    "#\n",
    "# For example, the [TextBlob](https://textblob.readthedocs.io/en/dev/index.html) tool provides a pretrained sentiment analyzer. Our spam classification task is not the same as sentiment classification, but we may believe that `SPAM` and `HAM` comments have different distributions of sentiment scores.\n",
    "# We'll focus on writing LFs for `HAM`, since we identified `SPAM` comments above.\n",
    "#\n",
    "# **A brief intro to `Preprocessor`s**\n",
    "#\n",
    "# A [Snorkel `Preprocessor`](https://snorkel.readthedocs.io/en/master/packages/_autosummary/preprocess/snorkel.preprocess.Preprocessor.html#snorkel.preprocess.Preprocessor)\n",
    "# is constructed from a black-box Python function that maps a data point to a new data point.\n",
    "# `LabelingFunction`s can use `Preprocessor`s, which lets us write LFs over transformed or enhanced data points.\n",
    "# We add the [`@preprocessor(...)` decorator](https://snorkel.readthedocs.io/en/master/packages/_autosummary/preprocess/snorkel.preprocess.preprocessor.html)\n",
    "# to preprocessing functions to create `Preprocessor`s.\n",
    "# `Preprocessor`s also have extra functionality, such as memoization\n",
    "# (i.e. input/output caching, so it doesn't re-execute for each LF that uses it).\n",
    "#\n",
    "# We'll start by creating a `Preprocessor` that runs `TextBlob` on our comments, then extracts the polarity and subjectivity scores.\n",
    "\n",
    "# %%\n",
    "from snorkel.preprocess import preprocessor\n",
    "from textblob import TextBlob\n",
    "\n",
    "\n",
    "@preprocessor(memoize=True)\n",
    "def textblob_sentiment(x):\n",
    "    scores = TextBlob(x.text)\n",
    "    x.polarity = scores.sentiment.polarity\n",
    "    x.subjectivity = scores.sentiment.subjectivity\n",
    "    return x\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# We can now pick a reasonable threshold and write a corresponding labeling function (note that it doesn't have to be perfect as the `LabelModel` will soon help us estimate each labeling function's accuracy and reweight their outputs accordingly):\n",
    "\n",
    "# %%\n",
    "@labeling_function(pre=[textblob_sentiment])\n",
    "def textblob_polarity(x):\n",
    "    return HAM if x.polarity > 0.9 else ABSTAIN\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# Let's do the same for the subjectivity scores.\n",
    "# This will run faster than the last cell, since we memoized the `Preprocessor` outputs.\n",
    "\n",
    "# %%\n",
    "@labeling_function(pre=[textblob_sentiment])\n",
    "def textblob_subjectivity(x):\n",
    "    return HAM if x.subjectivity >= 0.5 else ABSTAIN\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# Let's apply our LFs so we can analyze their performance.\n",
    "\n",
    "# %% {\"tags\": [\"md-exclude-output\"]}\n",
    "lfs = [textblob_polarity, textblob_subjectivity]\n",
    "\n",
    "applier = PandasLFApplier(lfs)\n",
    "L_train = applier.apply(df_train)\n",
    "\n",
    "# %%\n",
    "LFAnalysis(L_train, lfs).lf_summary()\n",
    "\n",
    "# %% [markdown]\n",
    "# **Again, these LFs aren't perfectâ€”note that the `textblob_subjectivity` LF has fairly high coverage and could have a high rate of false positives. We'll rely on Snorkel's `LabelModel` to estimate the labeling function accuracies and reweight and combine their outputs accordingly.**\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 3. Writing More Labeling Functions\n",
    "\n",
    "# %% [markdown]\n",
    "# If a single LF had high enough coverage to label our entire test dataset accurately, then we wouldn't need a classifier at all.\n",
    "# We could just use that single simple heuristic to complete the task.\n",
    "# But most problems are not that simple.\n",
    "# Instead, we usually need to **combine multiple LFs** to label our dataset, both to increase the size of the generated training set (since we can't generate training labels for data points that no LF voted on) and to improve the overall accuracy of the training labels we generate by factoring in multiple different signals.\n",
    "#\n",
    "# In the following sections, we'll show just a few of the many types of LFs that you could write to generate a training dataset for this problem.\n",
    "\n",
    "# %% [markdown]\n",
    "# ### a) Keyword LFs\n",
    "\n",
    "# %% [markdown]\n",
    "# For text applications, some of the simplest LFs to write are often just keyword lookups.\n",
    "# These will often follow the same execution pattern, so we can create a template and use the `resources` parameter to pass in LF-specific keywords.\n",
    "# Similar to the [`labeling_function` decorator](https://snorkel.readthedocs.io/en/master/packages/_autosummary/labeling/snorkel.labeling.labeling_function.html#snorkel.labeling.labeling_function),\n",
    "# the [`LabelingFunction` class](https://snorkel.readthedocs.io/en/master/packages/_autosummary/labeling/snorkel.labeling.LabelingFunction.html#snorkel.labeling.LabelingFunction)\n",
    "# wraps a Python function (the `f` parameter), and we can use the `resources` parameter to pass in keyword arguments (here, our keywords to lookup) to said function.\n",
    "\n",
    "# %%\n",
    "from snorkel.labeling import LabelingFunction\n",
    "\n",
    "\n",
    "def keyword_lookup(x, keywords, label):\n",
    "    if any(word in x.text.lower() for word in keywords):\n",
    "        return label\n",
    "    return ABSTAIN\n",
    "\n",
    "\n",
    "def make_keyword_lf(keywords, label=SPAM):\n",
    "    return LabelingFunction(\n",
    "        name=f\"keyword_{keywords[0]}\",\n",
    "        f=keyword_lookup,\n",
    "        resources=dict(keywords=keywords, label=label),\n",
    "    )\n",
    "\n",
    "\n",
    "\"\"\"Spam comments talk about 'my channel', 'my video', etc.\"\"\"\n",
    "keyword_my = make_keyword_lf(keywords=[\"my\"])\n",
    "\n",
    "\"\"\"Spam comments ask users to subscribe to their channels.\"\"\"\n",
    "keyword_subscribe = make_keyword_lf(keywords=[\"subscribe\"])\n",
    "\n",
    "\"\"\"Spam comments post links to other channels.\"\"\"\n",
    "keyword_link = make_keyword_lf(keywords=[\"http\"])\n",
    "\n",
    "\"\"\"Spam comments make requests rather than commenting.\"\"\"\n",
    "keyword_please = make_keyword_lf(keywords=[\"please\", \"plz\"])\n",
    "\n",
    "\"\"\"Ham comments actually talk about the video's content.\"\"\"\n",
    "keyword_song = make_keyword_lf(keywords=[\"song\"], label=HAM)\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# ### b) Pattern-matching LFs (regular expressions)\n",
    "\n",
    "# %% [markdown]\n",
    "# If we want a little more control over a keyword search, we can look for regular expressions instead.\n",
    "# The LF we developed above (`regex_check_out`) is an example of this.\n",
    "\n",
    "# %% [markdown]\n",
    "# ### c)  Heuristic LFs\n",
    "\n",
    "# %% [markdown]\n",
    "# There may other heuristics or \"rules of thumb\" that you come up with as you look at the data.\n",
    "# So long as you can express it in a function, it's a viable LF!\n",
    "\n",
    "# %%\n",
    "@labeling_function()\n",
    "def short_comment(x):\n",
    "    \"\"\"Ham comments are often short, such as 'cool video!'\"\"\"\n",
    "    return HAM if len(x.text.split()) < 5 else ABSTAIN\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# ### d) LFs with Complex Preprocessors\n",
    "\n",
    "# %% [markdown]\n",
    "# Some LFs rely on fields that aren't present in the raw data, but can be derived from it.\n",
    "# We can enrich our data (providing more fields for the LFs to refer to) using `Preprocessor`s.\n",
    "#\n",
    "# For example, we can use the fantastic NLP (natural language processing) tool [spaCy](https://spacy.io/) to add lemmas, part-of-speech (pos) tags, etc. to each token.\n",
    "# Snorkel provides a prebuilt preprocessor for spaCy called `SpacyPreprocessor` which adds a new field to the\n",
    "# data point containing a [spaCy `Doc` object](https://spacy.io/api/doc).\n",
    "# For more info, see the [`SpacyPreprocessor` documentation](https://snorkel.readthedocs.io/en/master/packages/_autosummary/preprocess/snorkel.preprocess.nlp.SpacyPreprocessor.html#snorkel.preprocess.nlp.SpacyPreprocessor).\n",
    "#\n",
    "#\n",
    "# If you prefer to use a different NLP tool, you can also wrap that as a `Preprocessor` and use it in the same way.\n",
    "# For more info, see the [`preprocessor` documentation](https://snorkel.readthedocs.io/en/master/packages/_autosummary/preprocess/snorkel.preprocess.preprocessor.html#snorkel.preprocess.preprocessor).\n",
    "\n",
    "# %% [markdown] {\"tags\": [\"md-exclude\"]}\n",
    "# If the spaCy English model wasn't already installed, the next cell may raise an exception.\n",
    "# If this happens, restart the kernel and re-execute the cells up to this point.\n",
    "\n",
    "# %%\n",
    "from snorkel.preprocess.nlp import SpacyPreprocessor\n",
    "\n",
    "# The SpacyPreprocessor parses the text in text_field and\n",
    "# stores the new enriched representation in doc_field\n",
    "spacy = SpacyPreprocessor(text_field=\"text\", doc_field=\"doc\", memoize=True)\n",
    "\n",
    "\n",
    "# %%\n",
    "@labeling_function(pre=[spacy])\n",
    "def has_person(x):\n",
    "    \"\"\"Ham comments mention specific people and are short.\"\"\"\n",
    "    if len(x.doc) < 20 and any([ent.label_ == \"PERSON\" for ent in x.doc.ents]):\n",
    "        return HAM\n",
    "    else:\n",
    "        return ABSTAIN\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# Because spaCy is such a common preprocessor for NLP applications, we also provide a\n",
    "# [prebuilt `labeling_function`-like decorator that uses spaCy](https://snorkel.readthedocs.io/en/master/packages/_autosummary/labeling/snorkel.labeling.lf.nlp.nlp_labeling_function.html#snorkel.labeling.lf.nlp.nlp_labeling_function).\n",
    "# This resulting LF is identical to the one defined manually above.\n",
    "\n",
    "# %%\n",
    "from snorkel.labeling.lf.nlp import nlp_labeling_function\n",
    "\n",
    "\n",
    "@nlp_labeling_function()\n",
    "def has_person_nlp(x):\n",
    "    \"\"\"Ham comments mention specific people and are short.\"\"\"\n",
    "    if len(x.doc) < 20 and any([ent.label_ == \"PERSON\" for ent in x.doc.ents]):\n",
    "        return HAM\n",
    "    else:\n",
    "        return ABSTAIN\n",
    "\n",
    "\n",
    "# %% [markdown]\n",
    "# **Adding new domain-specific preprocessors and LF types is a great way to contribute to Snorkel!\n",
    "# If you have an idea, feel free to reach out to the maintainers or submit a PR!**\n",
    "\n",
    "# %% [markdown]\n",
    "# ### e) Third-party Model LFs\n",
    "\n",
    "# %% [markdown]\n",
    "# We can also utilize other models, including ones trained for other tasks that are related to, but not the same as, the one we care about.\n",
    "# The TextBlob-based LFs we created above are great examples of this!\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 4. Combining Labeling Function Outputs with the Label Model\n",
    "\n",
    "# %% [markdown]\n",
    "# This tutorial demonstrates just a handful of the types of LFs that one might write for this task.\n",
    "# One of the key goals of Snorkel is _not_ to replace the effort, creativity, and subject matter expertise required to come up with these labeling functions, but rather to make it faster to write them, since **in Snorkel the labeling functions are assumed to be noisy, i.e. innaccurate, overlapping, etc.**\n",
    "# Said another way: the LF abstraction provides a flexible interface for conveying a huge variety of supervision signals, and the `LabelModel` is able to denoise these signals, reducing the need for painstaking manual fine-tuning.\n",
    "\n",
    "# %%\n",
    "lfs = [\n",
    "    keyword_my,\n",
    "    keyword_subscribe,\n",
    "    keyword_link,\n",
    "    keyword_please,\n",
    "    keyword_song,\n",
    "    regex_check_out,\n",
    "    short_comment,\n",
    "    has_person_nlp,\n",
    "    textblob_polarity,\n",
    "    textblob_subjectivity,\n",
    "]\n",
    "\n",
    "# %% [markdown]\n",
    "# With our full set of LFs, we can now apply these once again with `LFApplier` to get the label matrices.\n",
    "# The Pandas format provides an easy interface that many practitioners are familiar with, but it is also less optimized for scale.\n",
    "# For larger datasets, more compute-intensive LFs, or larger LF sets, you may decide to use one of the other data formats\n",
    "# that Snorkel supports natively, such as Dask DataFrames or PySpark DataFrames, and their corresponding applier objects.\n",
    "# For more info, check out the [Snorkel API documentation](https://snorkel.readthedocs.io/en/master/packages/labeling.html).\n",
    "\n",
    "# %% {\"tags\": [\"md-exclude-output\"]}\n",
    "applier = PandasLFApplier(lfs=lfs)\n",
    "L_train = applier.apply(df=df_train)\n",
    "L_test = applier.apply(df=df_test)\n",
    "\n",
    "# %%\n",
    "LFAnalysis(L=L_train, lfs=lfs).lf_summary()\n",
    "\n",
    "# %% [markdown] {\"tags\": [\"md-exclude\"]}\n",
    "# We see that our labeling functions vary in coverage, how much they overlap/conflict with one another, and almost certainly their accuracies as well.\n",
    "# We can view a histogram of how many LF labels the data points in our train set have to get an idea of our total coverage.\n",
    "\n",
    "# %% {\"tags\": [\"md-exclude\"]}\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# %matplotlib inline\n",
    "\n",
    "\n",
    "def plot_label_frequency(L):\n",
    "    plt.hist((L != ABSTAIN).sum(axis=1), density=True, bins=range(L.shape[1]))\n",
    "    plt.xlabel(\"Number of labels\")\n",
    "    plt.ylabel(\"Fraction of dataset\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_label_frequency(L_train)\n",
    "\n",
    "# %% [markdown] {\"tags\": [\"md-exclude\"]}\n",
    "# We see that over half of our `train` dataset data points have 2 or fewer labels from LFs.\n",
    "# Fortunately, the labels we do have can be used to train a classifier over the comment text directly, allowing this final machine learning model to generalize beyond what our labeling functions labeling.\n",
    "\n",
    "# %% [markdown]\n",
    "# Our goal is now to convert the labels from our LFs into a single _noise-aware_ probabilistic (or confidence-weighted) label per data point.\n",
    "# A simple baseline for doing this is to take the majority vote on a per-data point basis: if more LFs voted SPAM than HAM, label it SPAM (and vice versa).\n",
    "# We can test this with the\n",
    "# [`MajorityLabelVoter` baseline model](https://snorkel.readthedocs.io/en/master/packages/_autosummary/labeling/snorkel.labeling.model.baselines.MajorityLabelVoter.html#snorkel.labeling.model.baselines.MajorityLabelVoter).\n",
    "\n",
    "# %% {\"tags\": [\"md-exclude-output\"]}\n",
    "from snorkel.labeling.model import MajorityLabelVoter\n",
    "\n",
    "majority_model = MajorityLabelVoter()\n",
    "preds_train = majority_model.predict(L=L_train)\n",
    "\n",
    "# %%\n",
    "preds_train\n",
    "\n",
    "# %% [markdown]\n",
    "# However, as we can see from the summary statistics of our LFs in the previous section, they have varying properties and should not be treated identically. In addition to having varied accuracies and coverages, LFs may be correlated, resulting in certain signals being overrepresented in a majority-vote-based model. To handle these issues appropriately, we will instead use a more sophisticated Snorkel `LabelModel` to combine the outputs of the LFs.\n",
    "#\n",
    "# This model will ultimately produce a single set of noise-aware training labels, which are probabilistic or confidence-weighted labels. We will then use these labels to train a classifier for our task. For more technical details of this overall approach, see our [NeurIPS 2016](https://arxiv.org/abs/1605.07723) and [AAAI 2019](https://arxiv.org/abs/1810.02840) papers. For more info on the API, see the [`LabelModel` documentation](https://snorkel.readthedocs.io/en/master/packages/_autosummary/labeling/snorkel.labeling.model.label_model.LabelModel.html#snorkel.labeling.model.label_model.LabelModel).\n",
    "#\n",
    "# Note that no gold labels are used during the training process.\n",
    "# The only information we need is the label matrix, which contains the output of the LFs on our training set.\n",
    "# The `LabelModel` is able to learn weights for the labeling functions using only the label matrix as input.\n",
    "# We also specify the `cardinality`, or number of classes.\n",
    "\n",
    "# %% {\"tags\": [\"md-exclude-output\"]}\n",
    "from snorkel.labeling.model import LabelModel\n",
    "\n",
    "label_model = LabelModel(cardinality=2, verbose=True)\n",
    "label_model.fit(L_train=L_train, n_epochs=500, log_freq=100, seed=123)\n",
    "\n",
    "# %%\n",
    "majority_acc = majority_model.score(L=L_test, Y=Y_test, tie_break_policy=\"random\")[\n",
    "    \"accuracy\"\n",
    "]\n",
    "print(f\"{'Majority Vote Accuracy:':<25} {majority_acc * 100:.1f}%\")\n",
    "\n",
    "label_model_acc = label_model.score(L=L_test, Y=Y_test, tie_break_policy=\"random\")[\n",
    "    \"accuracy\"\n",
    "]\n",
    "print(f\"{'Label Model Accuracy:':<25} {label_model_acc * 100:.1f}%\")\n",
    "\n",
    "# %% [markdown]\n",
    "# The majority vote model or more sophisticated `LabelModel` could in principle be used directly as a classifier if the outputs of our labeling functions were made available at test time.\n",
    "# However, these models (i.e. these re-weighted combinations of our labeling function's votes) will abstain on the data points that our labeling functions don't cover (and additionally, may require slow or unavailable features to execute at test time).\n",
    "# In the next section, we will instead use the outputs of the `LabelModel` as training labels to train a discriminative classifier **which can generalize beyond the labeling function outputs** to see if we can improve performance further.\n",
    "# This classifier will also only need the text of the comment to make predictions, making it much more suitable for inference over unseen comments.\n",
    "# For more information on the properties of the label model, see the [Snorkel documentation](https://snorkel.readthedocs.io/en/master/packages/_autosummary/labeling/snorkel.labeling.model.label_model.LabelModel.html#snorkel.labeling.model.label_model.LabelModel).\n",
    "\n",
    "# %% [markdown] {\"tags\": [\"md-exclude\"]}\n",
    "# Let's briefly confirm that the labels the `LabelModel` produces are indeed probabilistic in nature.\n",
    "# The following histogram shows the confidences we have that each data point has the label SPAM.\n",
    "# The points we are least certain about will have labels close to 0.5.\n",
    "\n",
    "# %% {\"tags\": [\"md-exclude\"]}\n",
    "\n",
    "\n",
    "def plot_probabilities_histogram(Y):\n",
    "    plt.hist(Y, bins=10)\n",
    "    plt.xlabel(\"Probability of SPAM\")\n",
    "    plt.ylabel(\"Number of data points\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "probs_train = label_model.predict_proba(L=L_train)\n",
    "plot_probabilities_histogram(probs_train[:, SPAM])\n",
    "\n",
    "# %% [markdown]\n",
    "# ### Filtering out unlabeled data points\n",
    "\n",
    "# %% [markdown]\n",
    "# As we saw earlier, some of the data points in our `train` set received no labels from any of our LFs.\n",
    "# These data points convey no supervision signal and tend to hurt performance, so we filter them out before training using a\n",
    "# [built-in utility](https://snorkel.readthedocs.io/en/master/packages/_autosummary/labeling/snorkel.labeling.filter_unlabeled_dataframe.html#snorkel.labeling.filter_unlabeled_dataframe).\n",
    "\n",
    "# %%\n",
    "from snorkel.labeling import filter_unlabeled_dataframe\n",
    "\n",
    "df_train_filtered, probs_train_filtered = filter_unlabeled_dataframe(\n",
    "    X=df_train, y=probs_train, L=L_train\n",
    ")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 5. Training a Classifier\n",
    "\n",
    "# %% [markdown]\n",
    "# In this final section of the tutorial, we'll use the probabilistic training labels we generated in the last section to train a classifier for our task.\n",
    "# **The output of the Snorkel `LabelModel` is just a set of labels which can be used with most popular libraries for performing supervised learning, such as TensorFlow, Keras, PyTorch, Scikit-Learn, Ludwig, and XGBoost.**\n",
    "# In this tutorial, we use the well-known library [Scikit-Learn](https://scikit-learn.org).\n",
    "# **Note that typically, Snorkel is used (and really shines!) with much more complex, training data-hungry models, but we will use Logistic Regression here for simplicity of exposition.**\n",
    "\n",
    "# %% [markdown]\n",
    "# ### Featurization\n",
    "\n",
    "# %% [markdown]\n",
    "# For simplicity and speed, we use a simple \"bag of n-grams\" feature representation: each data point is represented by a one-hot vector marking which words or 2-word combinations are present in the comment text.\n",
    "\n",
    "# %% {\"tags\": [\"md-exclude-output\"]}\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 5))\n",
    "X_train = vectorizer.fit_transform(df_train_filtered.text.tolist())\n",
    "X_test = vectorizer.transform(df_test.text.tolist())\n",
    "\n",
    "# %% [markdown]\n",
    "# ### Scikit-Learn Classifier\n",
    "\n",
    "# %% [markdown]\n",
    "# As we saw in Section 4, the `LabelModel` outputs probabilistic (float) labels.\n",
    "# If the classifier we are training accepts target labels as floats, we can train on these labels directly (see describe the properties of this type of \"noise-aware\" loss in our [NeurIPS 2016 paper](https://arxiv.org/abs/1605.07723)).\n",
    "#\n",
    "# If we want to use a library or model that doesn't accept probabilistic labels (such as Scikit-Learn), we can instead replace each label distribution with the label of the class that has the maximum probability.\n",
    "# This can easily be done using the\n",
    "# [`probs_to_preds` helper method](https://snorkel.readthedocs.io/en/master/packages/_autosummary/utils/snorkel.utils.probs_to_preds.html#snorkel.utils.probs_to_preds).\n",
    "# We do note, however, that this transformation is lossy, as we no longer have values for our confidence in each label.\n",
    "\n",
    "# %%\n",
    "from snorkel.utils import probs_to_preds\n",
    "\n",
    "preds_train_filtered = probs_to_preds(probs=probs_train_filtered)\n",
    "\n",
    "# %% [markdown]\n",
    "# We then use these labels to train a classifier as usual.\n",
    "\n",
    "# %% {\"tags\": [\"md-exclude-output\"]}\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "sklearn_model = LogisticRegression(C=1e3, solver=\"liblinear\")\n",
    "sklearn_model.fit(X=X_train, y=preds_train_filtered)\n",
    "\n",
    "# %%\n",
    "print(f\"Test Accuracy: {sklearn_model.score(X=X_test, y=Y_test) * 100:.1f}%\")\n",
    "\n",
    "# %% [markdown]\n",
    "# **We observe an additional boost in accuracy over the `LabelModel` by multiple points! This is in part because the discriminative model generalizes beyond the labeling function's labels and makes good predictions on all data points, not just the ones covered by labeling functions.\n",
    "# By using the label model to transfer the domain knowledge encoded in our LFs to the discriminative model,\n",
    "# we were able to generalize beyond the noisy labeling heuristics**.\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Summary\n",
    "\n",
    "# %% [markdown]\n",
    "# In this tutorial, we accomplished the following:\n",
    "# * We introduced the concept of Labeling Functions (LFs) and demonstrated some of the forms they can take.\n",
    "# * We used the Snorkel `LabelModel` to automatically learn how to combine the outputs of our LFs into strong probabilistic labels.\n",
    "# * We showed that a classifier trained on a weakly supervised dataset can outperform an approach based on the LFs alone as it learns to generalize beyond the noisy heuristics we provide.\n",
    "\n",
    "# %% [markdown]\n",
    "# ### Next Steps\n",
    "\n",
    "# %% [markdown]\n",
    "# If you enjoyed this tutorial and you've already checked out the [Getting Started](https://snorkel.org/get-started/) tutorial, check out the [Tutorials](https://snorkel.org/use-cases/) page for other tutorials that you may find interesting, including demonstrations of how to use Snorkel\n",
    "#\n",
    "# * As part of a [hybrid crowdsourcing pipeline](https://snorkel.org/use-cases/crowdsourcing-tutorial)\n",
    "# * For [visual relationship detection over images](https://snorkel.org/use-cases/visual-relation-tutorial)\n",
    "# * For [information extraction over text](https://snorkel.org/use-cases/spouse-demo)\n",
    "# * For [data augmentation](https://snorkel.org/use-cases/02-spam-data-augmentation-tutorial)\n",
    "#\n",
    "# and more!\n",
    "# You can also visit the [Snorkel website](https://snorkel.org) or [Snorkel API documentation](https://snorkel.readthedocs.io) for more info!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
